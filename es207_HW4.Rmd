---
title: "ES207_HW4"
author: "Anshika Kandhway"
date: "2/17/2020"
output: html_document
---

**Helsel and Hirsh Textbook**

Q13.1 Compute both nonparametric and parametric 95% interval estimates for the median of the granodiorite data of exercise 2.3. Which is more appropriate for these data? Why?

a) Nonparametric intervals

Chloride concentration, in mg/L
```{r}

#Granodiorite
gran <- c(6.0, 0.5, 0.4, 0.7, 0.8, 6.0, 5.0, 0.6, 1.2, 
          0.3, 0.2, 0.5, 0.5, 10, 0.2, 0.2, 1.7, 3.0)

x <- sort(gran)
x
```

```{r}
#From Helshel and Hirsh textbook, when sample size (n) is less that 20 then non-parametric intervals are calculated using following:
#Lower interval, lo = x`+1 and 
#upper interval, hi= n-x`
#From Appendix table B5 (of H&H textbook) and Quantile, q= 50% and CI=95% Table A.1 (of Performance Evaluation Of Computer And Communication Systems by Jean-Yves Le Boudec), we have lower and upper values at 5th and 14th position respectively
#Here n=18
lo_np= x[c(5)]
hi_np= x[c(14)]
print(paste("Nonparametric lower interval is", lo_np))
print(paste("Nonparametric upper interval is", hi_np))
```


b) Parametric intervals

```{r}
y <- log(gran)
y
```

```{r}
mean_y <- mean(y)
gm <- exp(mean_y)
gm
```

```{r}
lo_par = exp(mean_y - (qt(0.975, df=18-1)* sqrt(var(y)/18)))
lo_par
hi_par = exp(mean_y + (qt(0.975, df=18-1)* sqrt(var(y)/18)))
hi_par
```

```{r}
print(paste("Parametric upper interval is", lo_par))
print(paste("Parametric upper interval is", hi_par))
```

```{r}
hist(gran)
```

Nonparmetric is preferable because data is small and non-normal (histogram). Also, for this the interval is wider than parametric interval which means there are more chances that median will be present in that interval.


Q3.4 Construct the most appropriate 95 percent interval estimates for the mean and median annual streamflows for the Conecuh River at Brantley, Alabama (data in Appendix C2).

```{r, echo=FALSE}
library(tidyverse)
#load Conecuh River data
crdata <- read_csv("Conecuh_River_apxc2.csv", col_names =TRUE, cols(
  Year = col_double(),
  `Flow (cfs)` = col_double()
))
crdata
```

```{r}
hist(crdata$`Flow (cfs)`)
```

Since, dataset is small and non-normal, nonparametric interval will be calculated.


Interval esrimates for mean
```{r}
lo_flow <- mean(crdata$`Flow (cfs)`) - 2*(sd(crdata$`Flow (cfs)`))
up_flow <- mean(crdata$`Flow (cfs)`) + 2*(sd(crdata$`Flow (cfs)`))
```


```{r}
CI <- predict(lm(crdata$`Flow (cfs)`~1),
interval = "confidence",
level = 0.95)
CI[1,]

print(paste("Interval for mean is 682.75 +/- 126.137"))
```

Interval esrimates for median
```{r}
#From Appendix table B5 (of H&H textbook) and Quantile, q= 50% and CI=95% Table A.1 (of Performance Evaluation Of Computer And Communication Systems by Jean-Yves Le Boudec)
#we have lower and upper values at 6th and 15th position respectively
sflow <- sort(crdata$`Flow (cfs)`)
med_sflow <- median(sflow)
lo_flowmd= sflow[c(5)]
hi_flowmd= sflow[c(14)]
print(paste("Median is", med_sflow))
print(paste("Nonparametric lower interval is", lo_flowmd))
print(paste("Nonparametric upper interval is", hi_flowmd))
```


**Qain Textbook**

Q4 Everglades Weland system


```{r}
#Loading data
"apa.data"<-
structure(.Data = list(apa = c(93.825, 96.1875, 120.6, 369.9, 299.113, 
	359.332, 380.968, 403.958, 214.933, 582.35299999999992, 319.235, 
	348.882, 71.5946, 139.626, 241.672, 194.283, 276.32100000000004, 
	190.817, 875.457, 705.587, 633.52099999999992, 723.176, 812.118, 
	756.529, 618.624, 1559.56, 797.196, 877.32, 421.2, 685.79999999999992,
	454.225, 536.405, 489.445, 379.874, 510.65, 399.854, 60.57, 47.97, 
	125.46, 108.768, 161.37200000000002, 173.13900000000002, 244.324, 
	207.04, 211.85, 844.357, 745.104, 928.722, 172.817, 181.218, 408.338, 
	84.826, 86.504, 933.111, 1027.6199999999998, 309.663, 277.385, 
	276.471, 292.325, 548.42499999999992, 537.08399999999992, 1183.77, 
	1157.47, 96.326, 102.73, 61.191, 173.02000000000002, 169.1, 155.16, 
	265.45, 191.16, 200.53, 192.44, 226.21, 313.93, 413.85, 
	261.14999999999996, 428.44, 551.79, 1327.6, 657.47, 834.11, 1106.3, 
	1240.3, 753.11, 891.18, 1013.9, 821.88, 971.93, 876.44, 141.966, 
	69.161, 57.338, 253.338, 217.47, 314.52499999999996, 
	179.90100000000002, 133.554, 213.815, 237.373, 252.995, 376.551, 
	22.92, 24.18, 29.01, 138.291, 171.066, 192.136, 240.68, 234.956, 
	267.392, 612.759, 585.486, 595.403), tp = c(11.3, 11.3, 11.3, 13, 13, 
	13, 9.1, 9.1, 9.1, 8.1, 8.1, 8.1, 13.7, 13.7, 13.7, 10.6, 10.6, 10.6, 
	15, 15, 15, 11, 11, 11, 9.1, 9.1, 9.1, 8.1, 8.1, 8.1, 8.1, 8.1, 8.1, 
	8.6, 8.6, 8.6, 11.1, 11.1, 11.1, 11.3, 11.3, 11.3, 7.2, 7.2, 7.2, 8.1,
	8.1, 8.1, 100.8, 100.8, 78.45, 87.65, 87.65, 24.7, 24.7, 12.35, 12.35,
	20.3, 20.3, 20.3, 20.3, 16.5, 16, 150.9, 150.9, 150.9, 100.5, 100.5, 
	100.5, 28.1, 28.1, 28.1, 28.1, 28.1, 28.1, 13.55, 13.55, 13.55, 18.9, 
	18.9, 18.9, 13.1, 13.1, 13.1, 8.7, 8.7, 8.7, 20.3, 20.3, 20.3, 95.1, 
	95.1, 95.1, 15, 15, 15, 10.6, 10.6, 10.6, 8.1, 8.1, 8.1, 92.9, 92.9, 
	92.9, 13.3, 13.3, 13.3, 9.1, 9.1, 9.1, 7.2, 7.2, 7.2)), row.names = 
	c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
	"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", 
	"25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", 
	"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", 
	"47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", 
	"58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68", 
	"69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79", 
	"80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90", 
	"91", "92", "93", "94", "95", "96", "97", "98", "99", "100", "101", 
	"102", "103", "104", "105", "106", "107", "108", "109", "110", "111", 
	"112", "113", "114"), class = "data.frame")
apa.data
```


(a) Compare the distributions of APA from sites with TP > 30 µg/L and APA from sites with TP < 30 µg/L using graphical tools we learned in Chapter 3.

```{r, echo=FALSE}
#Comparing distribution of APA for TP>30ug/l and TP<30ug/l
library(ggplot2)
library(dplyr)
apa_lo1 <-  (filter(apa.data, tp<30)%>%pull(apa))
apa_hi1 <-  (filter(apa.data, tp>30)%>%pull(apa))
```


```{r, echo=FALSE}
library(lattice)
qq_apa <- qqplot(x=apa_lo1, y=apa_hi1, plot.it=FALSE)
qq_apa <- as.data.frame(qq_apa)
xylim <- range(c(qq_apa$x, qq_apa$y))
ggplot (qq_apa, aes(x=x, y=y))+
            geom_point()+
            geom_abline(intercept = 0, slope = 1)+
            coord_fixed(ratio=1, xlim=xylim, ylim=xylim)+
            xlab("APA (TP<30µm/l)") + ylab("APA (TP>30µm/l)")+
            ggtitle("Compare APA data for TP>30µm/l and TP<30µm/l 
                    using QQ-plot")
```

(b) What is the nature of difference between the two populations of APA?
  
  The QQ plot for the two data shows that the difference between  data are multiplicative. This means that they have different means and standard deviations for their data distribution. Also, most pf the data are located near TP<30µg/l


(c) Use an appropriate test to determine whether the difference is statistically
signifcant and describe the result in non-technical terms.

```{r, echo=FALSE}
library(stats)
cor.test(apa.data$tp, apa.data$apa, method = "pearson", alternative = "greater")
```


```{r, echo=FALSE}
library(graphics)
plot (apa.data$tp, apa.data$apa, type= "p", col = "red", lwd = 2,
     main = "Plot between APA and TP", xlab = "TP", ylab = "APA") 
abline(lm(apa ~ tp, data = apa.data)) 

```

Using Pearson correlation text and regression plot, it can be seen that there is a positive correlation between phosphatase activity and total phosphorous concentration. In Phosphorous limited environment, APA is higher and vice-versa. This can be validated from above graph that APA goes down when P concentration is higher.






